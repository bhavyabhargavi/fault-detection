from tkinter import *
import tkinter
from tkinter import filedialog
from tkinter.filedialog import askopenfilename
from tkinter import simpledialog

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from lightgbm import LGBMClassifier
from sklearn.utils import resample
from sklearn.preprocessing import MinMaxScaler

from imblearn.under_sampling import RandomUnderSampler
from sklearn.ensemble import RandomForestClassifier


import joblib
import os
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report


main=tkinter.Tk()
main.title("Fault Detection and Classification in Photovoltaic Systems Using High-Frequency Data with ML Model")
main.geometry("1300x1200")
#main.configure(bg="seashell3")
title=tkinter.Label(main,text="Fault Detection and Classification in Photovoltaic Systems Using High-Frequency Data with ML Model",justify="center")
font = ('times', 16, 'bold')
title.config(bg='orange', fg='white')  
title.config(font=font)           
title.config(height=3, width=120)       
title.place(x=0,y=5)

global filename
global y,X_train,y_train,X_test,y_test,predict,undersampler
global dataset ,df
global test1,test,path
global le,scaler

labels=['MPPTFAULT','MPPTNOFAULT','LPPTFAULT','LPPTNOFAULT']
def Upload():
  global filename
  global dataset 
  filename=filedialog.askopenfilename()
  dataset=pd.read_csv(filename)
  text.insert(tkinter.END,filename+"loaded\n\n")
  text.insert(tkinter.END,str(dataset.shape))
  sns.set(style="darkgrid")  # Set the style of the plot
  plt.figure(figsize=(8, 6))  # Set the figure size
  ax = sns.countplot(x='Label', data=dataset)
  plt.title("Count Plot")  # Add a title to the plot
  plt.xlabel("Categories")  # Add label to x-axis
  plt.ylabel("Count")  # Add label to y-axis
# Annotate each bar with its count value  
 # Create a count plot

  for p in ax.patches:
        ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', fontsize=10, color='black', xytext=(0, 5),
                textcoords='offset points')

  plt.show()  # Display the plot

def preprocessing():
    global X,y,df,undersampler,le,scaler,pca
     
    le= LabelEncoder()
    dataset['Label']=  le.fit_transform(dataset['Label'])
    scaler = MinMaxScaler()
    df = scaler.fit_transform(dataset)
    X=dataset.iloc[:,1:14]
    y=dataset.iloc[:,-1]
    undersampler = RandomUnderSampler()
    X,y= undersampler.fit_resample(X, y)
    
    pca = PCA(n_components=10,svd_solver='full')  
    X = pca.fit_transform(X)
    text.insert(END,"\n"+str(X)+"\n\n")
    text.insert(END,"\n\n"+"X: "+str(X.shape)+"\n\n")
    text.insert(END,"\n\n"+"y: "+str(y.shape)+"\n\n")
    # Create a count plot
    sns.set(style="darkgrid")  # Set the style of the plot
    plt.figure(figsize=(8, 6))  # Set the figure size
# Replace 'dataset' with your actual DataFrame and 'Drug' with the column name
    ax = sns.countplot(x=labels, data=dataset, palette="Set3")
    
    plt.title("Count Plot")  # Add a title to the plot
    plt.xlabel("Categories")  # Add label to x-axis
    plt.ylabel("Count")  # Add label to y-axis
# Annotate each bar with its count value
    for p in ax.patches:
        ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', fontsize=10, color='black', xytext=(0, 5),
                textcoords='offset points')

    plt.show()  # Display the plot
    # Step 4: Perform PCA




def splitting():
    global X_train,X_test,y_train,y_test,y
    X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.20,random_state=77)
    text.insert(END,"\n\n"+"X_train: "+str(X_train.shape)+"\n\n")
    text.insert(END,"\n\n"+"Y_train: "+str(y_train.shape)+"\n\n")
    text.insert(END,"\n\n"+"X_test: "+str(X_test.shape)+"\n\n")
    text.insert(END,"\n\n"+"y_test: "+str(y_test.shape)+"\n\n")
        


#defining global variables to store accuracy and other metrics
precision = []
recall = []
fscore = []
accuracy = []

#function to calculate various metrics such as accuracy, precision etc
def calculateMetrics(algorithm, testY,predict):
    testY = testY.astype('int')
    predict = predict.astype('int')
    p = precision_score(testY, predict,average='macro') * 100
    r = recall_score(testY, predict,average='macro') * 100
    f = f1_score(testY, predict,average='macro') * 100
    a = accuracy_score(testY,predict)*100 
    accuracy.append(a)
    precision.append(p)
    recall.append(r)
    fscore.append(f)
    print(algorithm+' Accuracy    : '+str(a))
    print(algorithm+' Precision   : '+str(p))
    print(algorithm+' Recall      : '+str(r))
    print(algorithm+' FSCORE      : '+str(f))
    text.insert(tkinter.END,f"{algorithm} Accuracy    : {a}"+"\n\n")   
    text.insert(tkinter.END,f"{algorithm} Precision   : {p}"+"\n\n") 
    text.insert(tkinter.END,f"{algorithm} Recall      : {r}"+"\n\n") 
    text.insert(tkinter.END,f"{algorithm} FSCORE      : {f}"+"\n\n") 
    report=classification_report(predict, testY,target_names=labels)
    print('\n',algorithm+" classification report\n",report)
    conf_matrix = confusion_matrix(testY, predict) 
    plt.figure(figsize =(5, 5)) 
    ax = sns.heatmap(conf_matrix, xticklabels = labels, yticklabels = labels, annot = True, cmap="Blues" ,fmt ="g");
    ax.set_ylim([0,len(labels)])
    plt.title(algorithm+" Confusion matrix") 
    plt.ylabel('True class') 
    plt.xlabel('Predicted class') 
    plt.show()
def LGBM():
    global clf
    if os.path.exists('model/LGBMClassifier.pkl'):
    # Load the trained model from the file
        clf = joblib.load('model/LGBMClassifier.pkl')
        print("Model loaded successfully.")
        predict = clf.predict(X_test)
        calculateMetrics("LGBMClassifier", predict, y_test)
    else:
    # Train the model (assuming X_train and y_train are defined)
        clf = LGBMClassifier()
        clf.fit(X_train, y_train)
    # Save the trained model to a file
        joblib.dump(clf, 'model/LGBMClassifier.pkl')
        print("Model saved successfully.")
        predict = clf.predict(X_test)
        calculateMetrics("LGBMClassifier", predict, y_test)

def rfc():
    
    if os.path.exists('model/RFC.pkl'):
    # Load the trained model from the file
        rfc = joblib.load('model/RFC.pkl')
        print("Model loaded successfully.")
        predict = rfc.predict(X_test)
        calculateMetrics("RFC", predict, y_test)
    else:
    # Train the model (assuming X_train and y_train are defi}ned)
        rfc = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)
        rfc.fit(X_train, y_train)
    # Save the trained model to a file
        joblib.dump(rfc, 'model/RFC.pkl')
        print("Model saved successfully.")
        predict = rfc.predict(X_test)
        calculateMetrics("RFC", predict, y_test)
          

    #showing all algorithms performance values
    columns = ["Algorithm Name","Accuracy","Precison","Recall","FScore"]
    values = []
    algorithm_names = ["LGBMClassifier","RandomForestClassifier"]
    for i in range(len(algorithm_names)):
        values.append([algorithm_names[i],accuracy[i],precision[i],recall[i],fscore[i]])
    
    temp = pd.DataFrame(values,columns=columns)
    text.insert(END,"\n\n"+str(temp)+"\n\n")      

def pred():
    global test1,test,predict,path,pca
    path=filedialog.askopenfilename()
    test=pd.read_csv(path)
    le= LabelEncoder()
    test['Label']=  le.fit_transform(test['Label'])
    test['Label'].unique()
    test1=pca.fit_transform(test)
    
# Make predictions on the selected test data
    predict = clf.predict(test1)
# Loop through each prediction and print the corresponding row
    for i, p in enumerate(predict):
        if p == 0:
            print(test.iloc[i])
            print("Row {}:************************************************** MPPTFAULT".format(i))
        elif p==1:
            print(test.iloc[i])
            print("Row {}:************************************************** MPPTNOFAULT".format(i))
        elif p==2:
            print(test.iloc[i])
            print("Row {}:************************************************** LPPTFAULT".format(i))
        elif p==3:
            print(test.iloc[i])
            print("Row {}:************************************************** LPPTNOFAULT".format(i))
        

        
    test['predict']=predict 
    mapping = {0:'MPPTFAULT',1:'MPPTNOFAULT',2:'LPPTFAULT',3:'LPPTNOFAULT'}
    test['predict'] = test['predict'].map(mapping)
    text.insert(END,"\n\n"+".......Prediction......."+"\n\n")
    text.insert(END,"\n\n"+str(test)+"\n\n")


font1 = ('times', 12, 'bold')
text=Text(main,height=30,width=100,bg="ghost white")
scroll=Scrollbar(text)
text.configure(yscrollcommand=scroll.set)
text.place(x=50,y=120)
text.config(font=font1)

font1 = ('times', 13, 'bold')
upload = Button(main, text="Upload Dataset", command=Upload,bg="violet")
upload.place(x=900, y=150)
upload.config(font=font1)

preprocess = Button(main, text="Preprocess Dataset", command=preprocessing,bg="violet")
preprocess.place(x=900, y=200)
preprocess.config(font=font1)

split= Button(main, text="Splitting", command=splitting,bg="violet")
split.place(x=900, y=250)
split.config(font=font1)

dtc= Button(main, text="LGBM", command=LGBM,bg="violet")
dtc.place(x=900, y=300)
dtc.config(font=font1)

rfc= Button(main, text="RANDOM FOREST", command=rfc,bg="violet")
rfc.place(x=900, y=350)
rfc.config(font=font1)

p= Button(main, text="Prediction", command=pred,bg="violet")
p.place(x=900, y=400)
p.config(font=font1)  
main.config(bg='turquoise')  

main.mainloop()    
